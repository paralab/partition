@INPROCEEDINGS{parmetis,
  author={Karypis, G. and Kumar, V.},
  booktitle={Proceedings of International Conference on Parallel Processing}, 
  title={Parallel multilevel graph partitioning}, 
  year={1996},
  volume={},
  number={},
  pages={314-319},
  keywords={Partitioning algorithms;Sparse matrices;Parallel algorithms;Runtime;Concurrent computing},
  doi={10.1109/IPPS.1996.508075}}

@article{PT-Scotch,
  title = {PT-Scotch: A tool for efficient parallel graph ordering},
  journal = {Parallel Computing},
  volume = {34},
  number = {6},
  pages = {318-331},
  year = {2008},
  note = {Parallel Matrix Algorithms and Applications},
  issn = {0167-8191},
  doi = {https://doi.org/10.1016/j.parco.2007.12.001},
  url = {https://www.sciencedirect.com/science/article/pii/S0167819107001342},
  author = {C. Chevalier and F. Pellegrini},
  keywords = {Parallel graph ordering, Parallel nested dissection, Distributed-memory computer, Multi-threading},
}

@misc{meshes,
	title = {{D}ataset - {T}hingi10k},
  booktitle = {Faculty Digital Archive : NYU Libraries},
	howpublished = {\url{https://archive.nyu.edu/handle/2451/44304}},
	year = {},
	note = {[Accessed 05-07-2024]},
}


@Misc{petsc-web-page,
author = {Satish Balay and Shrirang Abhyankar and Mark~F. Adams and Jed Brown and Peter Brune
            and Kris Buschelman and Lisandro Dalcin and Victor Eijkhout and William~D. Gropp
            and Dinesh Kaushik and Matthew~G. Knepley
            and Lois Curfman McInnes and Karl Rupp and Barry~F. Smith
            and Stefano Zampini and Hong Zhang},
title =  {{PETS}c {W}eb page},
url =    {http://www.mcs.anl.gov/petsc},
howpublished = {\url{http://www.mcs.anl.gov/petsc}},
year = {2015}
}

@article{GMRES,
author = {Saad, Youcef and Schultz, Martin H},
title = {GMRES: a generalized minimal residual algorithm for solving nonsymmetric linear systems},
year = {1986},
issue_date = {July 1986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {7},
number = {3},
issn = {0196-5204},
journal = {SIAM J. Sci. Stat. Comput.},
month = {jul},
pages = {856–869},
numpages = {14}
}


@inproceedings{Frontera,
author = {Stanzione, Dan and West, John and Evans, R. Todd and Minyard, Tommy and Ghattas, Omar and Panda, Dhabaleswar K.},
title = {Frontera: The Evolution of Leadership Computing at the National Science Foundation},
year = {2020},
isbn = {9781450366892},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3311790.3396656},
doi = {10.1145/3311790.3396656},
abstract = {As part of the NSF’s cyberinfrastructure vision for a robust mix of high capability and capacity HPC systems, Frontera represents the most recent evolution of trans-petascale resources available to all open science research projects in the U.S. Debuting as the fifth largest supercomputer in the world, Frontera represents a robust and well-balanced HPC system designed to enable large-scale, productive science on day one of operations. The system provides a primary compute capability of nearly 39PF, delivered completely via more than 8,000 dual-socket servers with conventional Intel 8280 (“Cascade Lake”) processors. A unique configuration of both desktop GPUs and advanced floating units from NVIDIA enables both machine learning and scientific workloads, and the system delivers nearly 2TB/s of total filesystem bandwidth with 55 PB of usable Lustre disk-based storage and 3PB of all flash Lustre storage. A Mellanox InfiniBand (IB) interconnect provides very low latency with 100Gbps to each node, and 200Gbps between switches in a fat tree topology with minimal oversubscription for efficient communication, even in jobs that use the full system with complex communication patterns. The system hardware is complemented by a robust set of software services, including Application Programmer Interfaces (APIs) to support an evolving user base that increasingly demands productive access via science gateways and automated workflows, as well as a first-of-its-kind partnership with the three major cloud service providers to create a bridge between “traditional” HPC and the cloud infrastructure upon which research increasingly depends.},
booktitle = {Practice and Experience in Advanced Research Computing},
pages = {106–111},
numpages = {6},
keywords = {system design, supercomputer, cyberinfrastructure, HPC},
location = {Portland, OR, USA},
series = {PEARC '20}
}

@book{npcmpleteness,
   author = {Michael R. Garey and David S. Johnson},
   city = {New York},
   publisher = {Freeman},
   title = {Computers and Intractability : A guide to the theory of NP-Completeness},
   year = {1985},
}
